{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4319b202d5a3853c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Master's thesis - Lukas Meuris - training - loss functions\n",
    "\n",
    "This notebook contains the code to train the graphCast model. \n",
    "We use this notebook to traint the graphcast model with different loss-functions to see the influence of it on the model performance.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8602599318e266ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:32:29.980806Z",
     "start_time": "2024-04-25T15:29:54.800557Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# @title Pip install graphcast and dependencies\n",
    "\n",
    "#!pip install --upgrade https://github.com/deepmind/graphcast/archive/master.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c7bea05a9f82d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Installation and initialisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e247a864b8b52f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:33:27.376412Z",
     "start_time": "2024-04-25T15:33:24.026654Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import dataclasses\n",
    "import functools\n",
    "\n",
    "from google.cloud import storage\n",
    "from graphcast import autoregressive\n",
    "from graphcast import casting\n",
    "from graphcast import data_utils\n",
    "from graphcast import graphcast\n",
    "from graphcast import rollout\n",
    "from graphcast import normalization\n",
    "from graphcast import xarray_jax\n",
    "from graphcast import xarray_tree\n",
    "import haiku as hk\n",
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import xarray\n",
    "\n",
    "import optax\n",
    "\n",
    "import os\n",
    "import time\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53ac4e16811139b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Access data from GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f1a96b83614b53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:33:32.069605Z",
     "start_time": "2024-04-25T15:33:31.616191Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Authenticate with Google Cloud Storage\n",
    "# needed to get normalization data.\n",
    "\n",
    "gcs_client = storage.Client.create_anonymous_client()\n",
    "gcs_bucket = gcs_client.get_bucket(\"dm_graphcast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa6bbde098f5e90",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Load the Data and initialize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc6d61309fd5445",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Load the model parameters\n",
    "\n",
    "We use random parameters for the model initialization. \n",
    "We'll get random predictions, but we can change the model architecture.\n",
    "\n",
    "model parameters:\n",
    "- mesh size: specifies the internal graph representation of the earth. smaller meshes will run faster but will have worse outputs. The mesh size does not affect the number of parameters of the model. [4 - 6]\n",
    "- GNN message passing steps: specifies the number of message passing steps through the GNN layer of the model. [1 - 32]\n",
    "- Latent size: defines the feature size of the MLP's. [16, 32, 64 ,128, 256, 512]\n",
    "- levels: the amount of pressure levels. [13 or 37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174cfbbe28c88cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T14:59:17.048201Z",
     "start_time": "2024-04-25T14:59:17.043Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# choose model parameters\n",
    "random_mesh_size = 5 \n",
    "random_gnn_msg_steps = 8 \n",
    "random_latent_size = 128 \n",
    "random_levels = 13 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed00e6e-9dfb-4804-9c2e-b4356cc5a488",
   "metadata": {},
   "source": [
    "The following section initialises the initial empty parameters and state, and defines the model configuring with the parameters selected above.\n",
    "the task config defines the input and target variables to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f4d651a7513e25b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T14:59:19.057161Z",
     "start_time": "2024-04-25T14:59:19.042071Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelConfig(resolution=0, mesh_size=5, latent_size=128, gnn_msg_steps=8, hidden_layers=1, radius_query_fraction_edge_length=0.6, mesh2grid_edge_normalization_factor=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model parameters\n",
    "params = None\n",
    "state = {}\n",
    "model_config = graphcast.ModelConfig(\n",
    "    resolution=0,\n",
    "    mesh_size=random_mesh_size,\n",
    "    latent_size=random_latent_size,\n",
    "    gnn_msg_steps=random_gnn_msg_steps,\n",
    "    hidden_layers=1,\n",
    "    radius_query_fraction_edge_length=0.6)\n",
    "task_config = graphcast.TaskConfig(\n",
    "    input_variables=graphcast.TASK.input_variables,\n",
    "    target_variables=graphcast.TASK.target_variables,\n",
    "    forcing_variables=graphcast.TASK.forcing_variables,\n",
    "    pressure_levels=graphcast.PRESSURE_LEVELS[random_levels],\n",
    "    input_duration=graphcast.TASK.input_duration,\n",
    ")\n",
    "model_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1137cdf0973c0b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Load the ERA5 data\n",
    "\n",
    "ERA5 is used a ground truth to train the model on.\n",
    "To download the ERA5 data and transform it so that it works with the graphcast model, see 'download_data.ipynb'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b555036ff6ba79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T14:59:24.207615Z",
     "start_time": "2024-04-25T14:59:23.822646Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter-lukas/Masters-Thesis/ERA5_data/obs_data.zarr\n"
     ]
    }
   ],
   "source": [
    "# Define the relative path to the file\n",
    "relative_path = \"ERA5_data/obs_data.zarr\"\n",
    "\n",
    "# Get the absolute path by joining the current directory with the relative path\n",
    "absolute_path = os.path.join(os.path.dirname(os.getcwd()), relative_path)\n",
    "print(absolute_path)\n",
    "\n",
    "# Open the Zarr file using xarray\n",
    "obs_data = xarray.open_zarr(absolute_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f0775-6412-4315-a58c-562fd0e6ede8",
   "metadata": {},
   "source": [
    "## extract the training data\n",
    "We select the data from 1980 to 2019 to train our model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba5863be6de50f40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T14:59:29.611908Z",
     "start_time": "2024-04-25T14:59:29.588587Z"
    },
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#time slice: 1980-01-01T00:00:00.000000000 to 2019-12-31T00:00:00.000000000 - TRAINING\n",
    "train_data = obs_data.sel(time=slice('1980-01-01T00:00:00.000000000','2019-12-31T00:00:00.000000000'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad68aa3f-1d19-4a1f-aac9-7825c47de7f7",
   "metadata": {},
   "source": [
    "## choose the maximum number of training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "424741e3f3b393b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T14:59:27.452311Z",
     "start_time": "2024-04-25T14:59:27.448182Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_steps_max = 12  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d0a1b-b4af-4b81-a78a-91aa8b96501f",
   "metadata": {},
   "source": [
    "## extract initial training inputs, targets and forcings.\n",
    "these values don't matter that much, this is just used to initialise the model parameters with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64d1e62db03aaeaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T14:59:33.739762Z",
     "start_time": "2024-04-25T14:59:33.708680Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_inputs, train_targets, train_forcings = data_utils.extract_inputs_targets_forcings(\n",
    "    train_data, target_lead_times=slice(\"6h\", f\"{train_steps_max*6}h\"),\n",
    "    **dataclasses.asdict(task_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5416fc-18d0-4c3f-b6b8-a95b95127a19",
   "metadata": {},
   "source": [
    "## Load normalization data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "193ab3947cd265af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T14:59:38.210326Z",
     "start_time": "2024-04-25T14:59:36.595899Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with gcs_bucket.blob(\"stats/diffs_stddev_by_level.nc\").open(\"rb\") as f:\n",
    "    diffs_stddev_by_level = xarray.load_dataset(f).compute()\n",
    "with gcs_bucket.blob(\"stats/mean_by_level.nc\").open(\"rb\") as f:\n",
    "    mean_by_level = xarray.load_dataset(f).compute()\n",
    "with gcs_bucket.blob(\"stats/stddev_by_level.nc\").open(\"rb\") as f:\n",
    "    stddev_by_level = xarray.load_dataset(f).compute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f95ba9-4657-4313-a090-2038c32b825a",
   "metadata": {},
   "source": [
    "## Build jitted functions, and possibly initialize random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e60fc1c864187c8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T14:59:41.930757Z",
     "start_time": "2024-04-25T14:59:41.582129Z"
    },
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def construct_wrapped_graphcast(\n",
    "    model_config: graphcast.ModelConfig,\n",
    "    task_config: graphcast.TaskConfig):\n",
    "  \"\"\"Constructs and wraps the GraphCast Predictor.\"\"\"\n",
    "  # Deeper one-step predictor.\n",
    "  predictor = graphcast.GraphCast(model_config, task_config)\n",
    "\n",
    "  # Modify inputs/outputs to `graphcast.GraphCast` to handle conversion to\n",
    "  # from/to float32 to/from BFloat16.\n",
    "  predictor = casting.Bfloat16Cast(predictor)\n",
    "\n",
    "  # Modify inputs/outputs to `casting.Bfloat16Cast` so the casting to/from\n",
    "  # BFloat16 happens after applying normalization to the inputs/targets.\n",
    "  predictor = normalization.InputsAndResiduals(\n",
    "      predictor,\n",
    "      diffs_stddev_by_level=diffs_stddev_by_level,\n",
    "      mean_by_level=mean_by_level,\n",
    "      stddev_by_level=stddev_by_level)\n",
    "\n",
    "  # Wraps everything so the one-step model can produce trajectories.\n",
    "  predictor = autoregressive.Predictor(predictor, gradient_checkpointing=True)\n",
    "  return predictor\n",
    "\n",
    "\n",
    "@hk.transform_with_state\n",
    "def run_forward(model_config, task_config, inputs, targets_template, forcings):\n",
    "  predictor = construct_wrapped_graphcast(model_config, task_config)\n",
    "  return predictor(inputs, targets_template=targets_template, forcings=forcings)\n",
    "\n",
    "\n",
    "@hk.transform_with_state\n",
    "def loss_fn(model_config, task_config, inputs, targets, forcings):\n",
    "  predictor = construct_wrapped_graphcast(model_config, task_config)\n",
    "  loss, diagnostics = predictor.loss(inputs, targets, forcings)\n",
    "  return xarray_tree.map_structure(\n",
    "      lambda x: xarray_jax.unwrap_data(x.mean(), require_jax=True),\n",
    "      (loss, diagnostics))\n",
    "\n",
    "def grads_fn(params, state, inputs, targets, forcings, model_config, task_config):\n",
    "  def _aux(params, state, i, t, f):\n",
    "    (loss, diagnostics), next_state = loss_fn.apply(\n",
    "        params, state, jax.random.PRNGKey(0), model_config, task_config,\n",
    "        i, t, f)\n",
    "    return loss, (diagnostics, next_state)\n",
    "  (loss, (diagnostics, next_state)), grads = jax.value_and_grad(\n",
    "      _aux, has_aux=True)(params, state, inputs, targets, forcings)\n",
    "  return loss, diagnostics, next_state, grads\n",
    "\n",
    "# Jax doesn't seem to like passing configs as args through the jit. Passing it\n",
    "# in via partial (instead of capture by closure) forces jax to invalidate the\n",
    "# jit cache if you change configs.\n",
    "def with_configs(fn):\n",
    "  return functools.partial(\n",
    "      fn, model_config=model_config, task_config=task_config)\n",
    "\n",
    "# Always pass params and state, so the usage below are simpler\n",
    "def with_params(fn):\n",
    "  return functools.partial(fn, params=params, state=state)\n",
    "\n",
    "# Our models aren't stateful, so the state is always empty, so just return the\n",
    "# predictions. This is required by our rollout code, and generally simpler.\n",
    "def drop_state(fn):\n",
    "  return lambda **kw: fn(**kw)[0]\n",
    "\n",
    "init_jitted = jax.jit(with_configs(run_forward.init))\n",
    "\n",
    "if params is None:\n",
    "  params, state = init_jitted(\n",
    "      rng=jax.random.PRNGKey(0),\n",
    "      inputs=train_inputs.compute(),\n",
    "      targets_template=train_targets.compute(),\n",
    "      forcings=train_forcings.compute())\n",
    "\n",
    "loss_fn_jitted = drop_state(with_params(jax.jit(with_configs(loss_fn.apply))))\n",
    "grads_fn_jitted = jax.jit(with_configs(grads_fn))\n",
    "run_forward_jitted = drop_state(with_params(jax.jit(with_configs(\n",
    "    run_forward.apply))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb2774-d8bb-460d-a798-6e8f9d87b580",
   "metadata": {},
   "source": [
    "# Model training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da355b7-4050-45b5-b615-f9a35f2c4ddb",
   "metadata": {},
   "source": [
    "## 1. general training\n",
    "During general training we will loop over the entire dataset once, with only a single autoregressive step.\n",
    "the goal is to first learn the model how to do a single step well, before learning it to make multiple steps.\n",
    "\n",
    "We use the adamW optimiser with a lr with a cosine decay for 1e-3 to 0.\n",
    "\n",
    "The training loop first select a train_batch, this batch takes three time data steps (2 inputs, 1 target) and loads it into memory.\n",
    "then the training input and targets are extracted from this batch.\n",
    "a prediction is done on this batch and a loss and grad is computed based on the error between the prediction and the actual values.\n",
    "the model params are updates based on this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51f5e186-b16c-42ec-9aa8-c439832661d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of training steps\n",
    "train_steps = 1\n",
    "# data size\n",
    "N = train_data.sizes['time'] - train_steps - 4\n",
    "\n",
    "loss_array = []\n",
    "\n",
    "#setup optimiser\n",
    "lr = optax.cosine_decay_schedule(init_value=1e-3, decay_steps=N)\n",
    "optimiser = optax.adamw(lr, b1=0.9, b2=0.95, weight_decay=0.1)\n",
    "opt_state = optimiser.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4a76184-296c-4bfc-bcf3-7977ec38cebf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0  - Loss: 397.60156\n",
      "I: 1000  - Loss: 11.404785\n",
      "I: 2000  - Loss: 9.520996\n",
      "I: 3000  - Loss: 14.118164\n",
      "I: 4000  - Loss: 11.585449\n",
      "I: 5000  - Loss: 10.849609\n",
      "I: 6000  - Loss: 10.838379\n",
      "I: 7000  - Loss: 10.163086\n",
      "I: 8000  - Loss: 13.945801\n",
      "I: 9000  - Loss: 12.104492\n",
      "I: 10000  - Loss: 11.869629\n",
      "I: 11000  - Loss: 9.427246\n",
      "I: 12000  - Loss: 9.301758\n",
      "I: 13000  - Loss: 9.025391\n",
      "I: 14000  - Loss: 8.771484\n",
      "I: 15000  - Loss: 9.560547\n",
      "I: 16000  - Loss: 9.882324\n",
      "I: 17000  - Loss: 9.150879\n",
      "I: 18000  - Loss: 12.294434\n",
      "I: 19000  - Loss: 9.1015625\n",
      "I: 20000  - Loss: 8.869141\n",
      "I: 21000  - Loss: 11.0546875\n",
      "I: 22000  - Loss: 10.508789\n",
      "I: 23000  - Loss: 10.146484\n",
      "I: 24000  - Loss: 8.806152\n",
      "I: 25000  - Loss: 8.782227\n",
      "I: 26000  - Loss: 8.216309\n",
      "I: 27000  - Loss: 8.443359\n",
      "I: 28000  - Loss: 9.193848\n",
      "I: 29000  - Loss: 11.162598\n",
      "I: 30000  - Loss: 9.328125\n",
      "I: 31000  - Loss: 10.810059\n",
      "I: 32000  - Loss: 8.931152\n",
      "I: 33000  - Loss: 10.552734\n",
      "I: 34000  - Loss: 9.779785\n",
      "I: 35000  - Loss: 8.922852\n",
      "I: 36000  - Loss: 9.691406\n",
      "I: 37000  - Loss: 8.339844\n",
      "I: 38000  - Loss: 9.173828\n",
      "I: 39000  - Loss: 8.956055\n",
      "I: 40000  - Loss: 8.791016\n",
      "I: 41000  - Loss: 9.266602\n",
      "I: 42000  - Loss: 9.1484375\n",
      "I: 43000  - Loss: 9.164551\n",
      "I: 44000  - Loss: 8.763184\n",
      "I: 45000  - Loss: 8.081543\n",
      "I: 46000  - Loss: 8.963867\n",
      "I: 47000  - Loss: 8.365723\n",
      "I: 48000  - Loss: 9.864258\n",
      "I: 49000  - Loss: 9.366699\n",
      "I: 50000  - Loss: 8.897461\n",
      "I: 51000  - Loss: 7.927246\n",
      "I: 52000  - Loss: 7.705078\n",
      "I: 53000  - Loss: 7.925293\n",
      "I: 54000  - Loss: 8.983887\n",
      "I: 55000  - Loss: 8.160156\n",
      "I: 56000  - Loss: 8.05127\n",
      "I: 57000  - Loss: 8.255371\n",
      "I: 58000  - Loss: 10.036621\n",
      "general training finished.\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "for i in range(N):\n",
    "    train_batch = train_data.isel(time=slice(i, i + train_steps + 2))\n",
    "    train_batch = train_batch.compute()\n",
    "\n",
    "    train_inputs, train_targets, train_forcings = data_utils.extract_inputs_targets_forcings(\n",
    "    train_batch, target_lead_times=slice(\"6h\", f\"{train_steps*6}h\"),\n",
    "    **dataclasses.asdict(task_config))\n",
    "\n",
    "    # calculate loss and gradients\n",
    "    loss, diagnostics, next_state, grads = grads_fn_jitted(params, state, train_inputs, train_targets, train_forcings)\n",
    "\n",
    "    # update\n",
    "    updates, opt_state = optimiser.update(grads, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    \n",
    "    loss_array.append(loss)\n",
    "    if i%1000 == 0:\n",
    "        print(\"I:\", i , \" - Loss:\", loss)\n",
    "\n",
    "print(\"general training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f311cb20-21db-4487-ac37-e3eed7216f0e",
   "metadata": {},
   "source": [
    "## 2.Fine tuning\n",
    "during fine tuning we select the last 11000 time steps of our whole dataset and use that to finetune the model to work with more autoregressive steps.\n",
    "we increase the amount of autoregressive steps every 1000 loops from 2 to 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cabf7a0-c3ec-4d67-be49-feaef809c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data size\n",
    "N = train_data.sizes['time'] - train_steps_max - 4\n",
    "# only take the last 11000 time steps\n",
    "Ksteps = 11000\n",
    "Ktime = N - Ksteps\n",
    "train_steps = 1\n",
    "\n",
    "#setup optimiser\n",
    "lr = 1e-7\n",
    "optimiser = optax.adamw(lr, b1=0.9, b2=0.95, weight_decay=0.1)\n",
    "opt_state = optimiser.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5b8d12e-187b-4a2b-a987-8b395bc1d240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0  - steps:  2  - Loss: 8.841797\n",
      "I: 1000  - steps:  3  - Loss: 8.53125\n",
      "I: 2000  - steps:  4  - Loss: 9.25\n",
      "I: 3000  - steps:  5  - Loss: 11.28125\n",
      "I: 4000  - steps:  6  - Loss: 8.6625\n",
      "I: 5000  - steps:  7  - Loss: 13.083334\n",
      "I: 6000  - steps:  8  - Loss: 9.0\n",
      "I: 7000  - steps:  9  - Loss: 17.625\n",
      "I: 8000  - steps:  10  - Loss: 10.572917\n",
      "I: 9000  - steps:  11  - Loss: 11.76875\n",
      "I: 10000  - steps:  12  - Loss: 14.232955\n",
      "finetuning training finished.\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "for i in range(Ksteps):\n",
    "    \n",
    "    train_batch = train_data.isel(time=slice(Ktime + i,Ktime +  i + train_steps + 2))\n",
    "    train_batch = train_batch.compute()\n",
    "\n",
    "    train_inputs, train_targets, train_forcings = data_utils.extract_inputs_targets_forcings(\n",
    "    train_batch, target_lead_times=slice(\"6h\", f\"{train_steps*6}h\"),\n",
    "    **dataclasses.asdict(task_config))\n",
    "\n",
    "    # calculate loss and gradients\n",
    "    loss, diagnostics, next_state, grads = grads_fn_jitted(params, state, train_inputs, train_targets, train_forcings)\n",
    "\n",
    "    # update\n",
    "    updates, opt_state = optimiser.update(grads, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    \n",
    "    loss_array.append(loss)\n",
    "    if i%1000 == 0:\n",
    "        train_steps += 1\n",
    "        print(\"I:\", i ,\" - steps: \",train_steps,\" - Loss:\", loss)\n",
    "        \n",
    "\n",
    "print(\"finetuning training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a73a19c6364468",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Save the model params to file\n",
    "after training is complete we will save the model parameters to file.\n",
    "Afterwards the parameters can be loaded in again to do predictions with the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7382ba7b-b0b1-4e43-80d1-15537cabc139",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def flatten_dict(d, parent_key='', sep='//'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "def save_model_params(d, file_path):\n",
    "    flat_dict = flatten_dict(d)\n",
    "    # Convert JAX arrays to NumPy for saving\n",
    "    np_dict = {k: np.array(v) if isinstance(v, jnp.ndarray) else v for k, v in flat_dict.items()}\n",
    "    np.savez(file_path, **np_dict)\n",
    "\n",
    "params_path = os.path.join('../models', 'params_64x32_rae.npz')\n",
    "save_model_params(params, params_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239c5fb7cab06b29",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now, our trained model is saved to a file ,which can be used to load and run again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MTLMenv",
   "language": "python",
   "name": "mtlmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
